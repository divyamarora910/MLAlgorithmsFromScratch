{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "loans=pd.read_csv(r\"C:\\Users\\divyam.arora\\Desktop\\New Folder 3\\machine-learning-specialization-master\\course-3\\datasets\\lending-club-data.csv\",sep=',',low_memory=False)\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans=loans[loans['home_ownership']!='OTHER']\n",
    "total_loans=loans[loans['safe_loans']==1]\n",
    "risky_loans=loans[loans['safe_loans']==-1]\n",
    "total_loans=total_loans.sample(frac=(len(risky_loans)/len(total_loans)),random_state=1)\n",
    "total_loans=total_loans.append(risky_loans)\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "total_loans = total_loans[features + [target]]\n",
    "\n",
    "total_loans=pd.get_dummies(total_loans, columns=[\"home_ownership\"])\n",
    "total_loans=pd.get_dummies(total_loans, columns=[\"term\"])\n",
    "total_loans=pd.get_dummies(total_loans, columns=[\"emp_length\"])\n",
    "total_loans=pd.get_dummies(total_loans, columns=[\"grade\"])\n",
    "train_data,test_data=train_test_split(total_loans,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    ## YOUR CODE HERE\n",
    "    safe_loans=len(labels_in_node[labels_in_node==1])\n",
    "    \n",
    "    # Count the number of -1's (risky loans)\n",
    "    ## YOUR CODE HERE\n",
    "    risky_loans=len(labels_in_node[labels_in_node==-1])\n",
    "                \n",
    "    # Return the number of mistakes that the majority classifier makes.\n",
    "    ## YOUR CODE HERE\n",
    "    if safe_loans>risky_loans:\n",
    "        return risky_loans\n",
    "    else:\n",
    "        return safe_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n",
      "Test passed!\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "example_labels = pd.Series([-1, -1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 1 failed... try again!')\n",
    "\n",
    "# Test case 2\n",
    "example_labels = pd.Series([-1, -1, 1, 1, 1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 2 failed... try again!')\n",
    "    \n",
    "# Test case 3\n",
    "example_labels = pd.Series([-1, -1, -1, -1, -1, 1, 1])\n",
    "if intermediate_node_num_mistakes(example_labels) == 2:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test 3 failed... try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    target_values = data[target]\n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        ## YOUR CODE HERE\n",
    "        right_split = data[data[feature] == 1] \n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        # YOUR CODE HERE\n",
    "        left_mistakes = intermediate_node_num_mistakes(left_split[target])\n",
    "        #print('no of left mistakes is ',left_mistakes)\n",
    "\n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        ## YOUR CODE HERE\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target])\n",
    "        #print('no of right mistakes is ',left_mistakes)\n",
    "            \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        ## YOUR CODE HERE\n",
    "        error = ((left_mistakes+right_mistakes)/num_data_points)\n",
    "\n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        ## YOUR CODE HERE\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "        \n",
    "    \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_Set=total_loans.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_Set.remove('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "if best_splitting_feature(total_loans, feature_Set, 'safe_loans') == 'term_ 36 months':\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf':True,\n",
    "            'prediction':None}   ## YOUR CODE HERE\n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = 1      ## YOUR CODE HERE\n",
    "    else:\n",
    "        leaf['prediction'] = -1         ## YOUR CODE HERE\n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]#output series left in current node\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "\n",
    "    # Stopping condition 1\n",
    "    # (Check if there are mistakes at current node.\n",
    "    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n",
    "    if  intermediate_node_num_mistakes(target_values)== 0:  ## YOUR CODE HERE\n",
    "        print(\"Stopping condition 1 reached.\")     \n",
    "        # If not mistakes at current node, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n",
    "    if remaining_features ==[]:   ## YOUR CODE HERE\n",
    "        print(\"Stopping condition 2 reached.\")    \n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >=max_depth:  ## YOUR CODE HERE\n",
    "        print(\"Reached maximum depth. Stopping for now.\")\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    ## YOUR CODE HERE\n",
    "    splitting_feature=best_splitting_feature(data, remaining_features, 'safe_loans')\n",
    "    print('the new splitting fetaure is:',splitting_feature)\n",
    "\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]      ## YOUR CODE HERE\n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature %s. (%s, %s)\" % (\\\n",
    "                                             splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if(len(left_split) == len(data)):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    if(len(right_split) == len(data)):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n",
    "    ## YOUR CODE HERE\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)\n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (46218 data points).\n",
      "the new splitting fetaure is: term_ 36 months\n",
      "Split on feature term_ 36 months. (11582, 34636)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (11582 data points).\n",
      "the new splitting fetaure is: grade_A\n",
      "Split on feature grade_A. (11432, 150)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (11432 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (5100, 6332)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5100 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6332 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (150 data points).\n",
      "the new splitting fetaure is: emp_length_n/a\n",
      "Split on feature emp_length_n/a. (143, 7)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (143 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (7 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (34636 data points).\n",
      "the new splitting fetaure is: grade_D\n",
      "Split on feature grade_D. (28823, 5813)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28823 data points).\n",
      "the new splitting fetaure is: grade_E\n",
      "Split on feature grade_E. (27240, 1583)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (27240 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1583 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5813 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (3789, 2024)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3789 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2024 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "small_data_decision_tree = decision_tree_create(total_loans,feature_Set,'safe_loans', max_depth = 3)\n",
    "if count_nodes(small_data_decision_tree) == 15:\n",
    "    print('Test passed!')\n",
    "else:\n",
    "    print('Test failed... try again!')\n",
    "    print('Number of nodes found                :', count_nodes(small_data_decision_tree))\n",
    "    print('Number of nodes that should be there : 15') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (46218 data points).\n",
      "the new splitting fetaure is: term_ 36 months\n",
      "Split on feature term_ 36 months. (11582, 34636)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (11582 data points).\n",
      "the new splitting fetaure is: grade_A\n",
      "Split on feature grade_A. (11432, 150)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (11432 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (5100, 6332)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5100 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (4180, 920)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4180 data points).\n",
      "the new splitting fetaure is: home_ownership_RENT\n",
      "Split on feature home_ownership_RENT. (0, 4180)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (920 data points).\n",
      "the new splitting fetaure is: home_ownership_RENT\n",
      "Split on feature home_ownership_RENT. (920, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (6332 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (6332, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (150 data points).\n",
      "the new splitting fetaure is: emp_length_n/a\n",
      "Split on feature emp_length_n/a. (143, 7)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (143 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (39, 104)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (39 data points).\n",
      "the new splitting fetaure is: emp_length_7 years\n",
      "Split on feature emp_length_7 years. (38, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (38 data points).\n",
      "the new splitting fetaure is: emp_length_8 years\n",
      "Split on feature emp_length_8 years. (37, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (37 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (104 data points).\n",
      "the new splitting fetaure is: emp_length_5 years\n",
      "Split on feature emp_length_5 years. (99, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (99 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (99, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (7 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (3, 4)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (4, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (34636 data points).\n",
      "the new splitting fetaure is: grade_D\n",
      "Split on feature grade_D. (28823, 5813)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (28823 data points).\n",
      "the new splitting fetaure is: grade_E\n",
      "Split on feature grade_E. (27240, 1583)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (27240 data points).\n",
      "the new splitting fetaure is: grade_F\n",
      "Split on feature grade_F. (26786, 454)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (26786 data points).\n",
      "the new splitting fetaure is: grade_C\n",
      "Split on feature grade_C. (17847, 8939)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (17847 data points).\n",
      "the new splitting fetaure is: grade_G\n",
      "Split on feature grade_G. (17715, 132)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (17715 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (132 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (8939 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (5346, 3593)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5346 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (3593 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (454 data points).\n",
      "the new splitting fetaure is: emp_length_8 years\n",
      "Split on feature emp_length_8 years. (437, 17)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (437 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (291, 146)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (291 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (146 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (17 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (11, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1583 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (1063, 520)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1063 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (937, 126)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (937 data points).\n",
      "the new splitting fetaure is: emp_length_9 years\n",
      "Split on feature emp_length_9 years. (910, 27)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (910 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (27 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (126 data points).\n",
      "the new splitting fetaure is: emp_length_3 years\n",
      "Split on feature emp_length_3 years. (120, 6)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (120 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (6 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (520 data points).\n",
      "the new splitting fetaure is: emp_length_6 years\n",
      "Split on feature emp_length_6 years. (497, 23)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (497 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (497, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (23 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (23, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (5813 data points).\n",
      "the new splitting fetaure is: home_ownership_MORTGAGE\n",
      "Split on feature home_ownership_MORTGAGE. (3789, 2024)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3789 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (3257, 532)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (3257 data points).\n",
      "the new splitting fetaure is: home_ownership_RENT\n",
      "Split on feature home_ownership_RENT. (0, 3257)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (532 data points).\n",
      "the new splitting fetaure is: home_ownership_RENT\n",
      "Split on feature home_ownership_RENT. (532, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2024 data points).\n",
      "the new splitting fetaure is: emp_length_9 years\n",
      "Split on feature emp_length_9 years. (1937, 87)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1937 data points).\n",
      "the new splitting fetaure is: emp_length_5 years\n",
      "Split on feature emp_length_5 years. (1784, 153)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1784 data points).\n",
      "the new splitting fetaure is: emp_length_4 years\n",
      "Split on feature emp_length_4 years. (1652, 132)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1652 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (132 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (153 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (153, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (87 data points).\n",
      "the new splitting fetaure is: home_ownership_OWN\n",
      "Split on feature home_ownership_OWN. (87, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree=decision_tree_create(total_loans,feature_Set,'safe_loans', max_depth = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x is a dataframe with only one row test case\n",
    "#tree is a dictionary of root node\n",
    "#anotate decides if we want to see the path or not.\n",
    "def classify(tree, x, annotate = False):\n",
    "    \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print(\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        #print(x.columns)\n",
    "        split_feature_value = x.head(1)[tree['splitting_feature']].values[0]\n",
    "        if annotate: \n",
    "            print(\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'],x,annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)['safe_loans'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print('Predicted class: %s ' % classify(my_decision_tree, test_data.head(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term_ 36 months = 1\n",
      "Split on grade_D = 0\n",
      "Split on grade_E = 0\n",
      "Split on grade_F = 0\n",
      "Split on grade_C = 0\n",
      "Split on grade_G = 0\n",
      "At leaf, predicting 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree, test_data.head(1),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data, target):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction =data.apply(lambda x: classify(tree, pd.DataFrame(x).transpose()),axis=1)\n",
    "    total_examples=len(prediction)\n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    ## YOUR CODE HERE\n",
    "    mistakes=(prediction!=data[target]).value_counts()[True]\n",
    "    \n",
    "    return (mistakes/total_examples)*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error=evaluate_classification_error(my_decision_tree,test_data,'safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.094331458243182"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print(\"(leaf, label: %s)\" % tree['prediction'])\n",
    "        return None\n",
    "    split_feature, split_value = split_name.rsplit('_',1)\n",
    "    print('                       %s' % name)\n",
    "    print('         |---------------|----------------|')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       root\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [term_ 36 months == 0]               [term_ 36 months == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_tree(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print(\"(leaf, label: %s)\" % tree['prediction'])\n",
    "        return None\n",
    "    split_feature, split_value = split_name.rsplit('_',1)\n",
    "    print('                       %s' % name)\n",
    "    print('         |---------------|----------------|')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('  [{0} == 0]               [{0} == 1]    '.format(split_name))\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('         |                                |')\n",
    "    print('    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree')))\n",
    "    if tree['left'] is not None:\n",
    "        print_tree(tree['left'],'')\n",
    "    if tree['right'] is not None:\n",
    "        print_tree(tree['right'],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       term_ 36 months\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [grade_A == 0]               [grade_A == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (subtree)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left'], my_decision_tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       grade_A\n",
      "         |---------------|----------------|\n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "  [home_ownership_MORTGAGE == 0]               [home_ownership_MORTGAGE == 1]    \n",
      "         |                                |\n",
      "         |                                |\n",
      "         |                                |\n",
      "    (subtree)                         (leaf, label: -1)\n"
     ]
    }
   ],
   "source": [
    "print_stump(my_decision_tree['left']['left'], my_decision_tree['left']['splitting_feature'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
